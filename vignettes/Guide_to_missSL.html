<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Pan Zhao, Nicolas Gatulle, Julie Josse and Antoine Chambaz" />

<meta name="date" content="2022-09-05" />

<title>Guide to missSuperLearner</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Guide to missSuperLearner</h1>
<h4 class="author">Pan Zhao, Nicolas Gatulle, Julie Josse and Antoine
Chambaz</h4>
<h4 class="date">September 5, 2022</h4>


<div id="TOC">
<ul>
<li><a href="#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#dataset" id="toc-dataset"><span class="toc-section-number">2</span> Dataset</a></li>
<li><a href="#review-available-models" id="toc-review-available-models"><span class="toc-section-number">3</span> Review available models</a></li>
<li><a href="#fit-individual-models" id="toc-fit-individual-models"><span class="toc-section-number">4</span>
Fit individual models</a></li>
<li><a href="#fit-multiple-models" id="toc-fit-multiple-models"><span class="toc-section-number">5</span> Fit multiple models</a></li>
<li><a href="#predict-on-new-data" id="toc-predict-on-new-data"><span class="toc-section-number">6</span> Predict on new data</a></li>
<li><a href="#fit-ensemble-with-external-cross-validation" id="toc-fit-ensemble-with-external-cross-validation"><span class="toc-section-number">7</span> Fit ensemble with external
cross-validation</a></li>
<li><a href="#customize-a-model-hyperparameter" id="toc-customize-a-model-hyperparameter"><span class="toc-section-number">8</span> Customize a model
hyperparameter</a></li>
<li><a href="#test-algorithm-with-multiple-hyperparameter-settings" id="toc-test-algorithm-with-multiple-hyperparameter-settings"><span class="toc-section-number">9</span> Test algorithm with multiple
hyperparameter settings</a></li>
<li><a href="#multicore-parallelization" id="toc-multicore-parallelization"><span class="toc-section-number">10</span> Multicore parallelization</a></li>
<li><a href="#weight-distribution-for-superlearner" id="toc-weight-distribution-for-superlearner"><span class="toc-section-number">11</span> Weight distribution for
SuperLearner</a></li>
<li><a href="#feature-selection-screening" id="toc-feature-selection-screening"><span class="toc-section-number">12</span> Feature selection
(screening)</a></li>
<li><a href="#optimize-for-auc" id="toc-optimize-for-auc"><span class="toc-section-number">13</span> Optimize for AUC</a></li>
<li><a href="#references" id="toc-references"><span class="toc-section-number">14</span> References</a></li>
</ul>
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(missSuperLearner)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required package: SuperLearner</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required package: nnls</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required package: gam</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required package: splines</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required package: foreach</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loaded gam 1.20.2</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Super Learner</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Version: 2.0-28</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Package created on 2021-05-04</span></span></code></pre></div>
<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This vignette is a practical guide for using the
<code>missSuperLearner</code> package, which builds on the
<code>SuperLearner</code> package. If you are unfamiliar with the
<code>SuperLearner</code> package, it is advisable to read this <a href="https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html">Guide
to SuperLearner</a> first.</p>
</div>
<div id="dataset" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Dataset</h1>
<p>We use the <code>diabetes</code> dataset which is available from the
<code>VIM</code> package.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset from the VIM package</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(diabetes, <span class="at">package =</span> <span class="st">&quot;VIM&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Info of the diabetes dataset</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>?VIM<span class="sc">::</span>diabetes</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of the dataset</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(diabetes)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Pregnancies        Glucose      BloodPressure    SkinThickness  </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   : 1.000   Min.   : 44.0   Min.   : 24.00   Min.   : 7.00  </span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.: 2.000   1st Qu.: 99.0   1st Qu.: 64.00   1st Qu.:22.00  </span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median : 4.000   Median :117.0   Median : 72.00   Median :29.00  </span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   : 4.495   Mean   :121.7   Mean   : 72.41   Mean   :29.15  </span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.: 7.000   3rd Qu.:141.0   3rd Qu.: 80.00   3rd Qu.:36.00  </span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  </span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  NA&#39;s   :111      NA&#39;s   :5       NA&#39;s   :35       NA&#39;s   :227    </span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     Insulin            BMI        DiabetesPedigreeFunction      Age       </span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   : 14.00   Min.   :18.20   Min.   :0.0780           Min.   :21.00  </span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.: 76.25   1st Qu.:27.50   1st Qu.:0.2437           1st Qu.:24.00  </span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median :125.00   Median :32.30   Median :0.3725           Median :29.00  </span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   :155.55   Mean   :32.46   Mean   :0.4719           Mean   :33.24  </span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:190.00   3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00  </span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :846.00   Max.   :67.10   Max.   :2.4200           Max.   :81.00  </span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  NA&#39;s   :374      NA&#39;s   :11                                              </span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Outcome  </span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  no :500  </span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  yes:268  </span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing data</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(diabetes))</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              Pregnancies                  Glucose            BloodPressure </span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                      111                        5                       35 </span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            SkinThickness                  Insulin                      BMI </span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                      227                      374                       11 </span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; DiabetesPedigreeFunction                      Age                  Outcome </span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                        0                        0                        0</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the outcome variable from the data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>outcome <span class="ot">&lt;-</span> diabetes<span class="sc">$</span>Outcome</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataframe to contain the explanatory variables</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">subset</span>(diabetes, <span class="at">select =</span> <span class="sc">-</span>Outcome)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Check structure of our dataframe</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &#39;data.frame&#39;:    768 obs. of  8 variables:</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ Pregnancies             : int  6 1 8 1 NA 5 3 10 2 8 ...</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ Glucose                 : int  148 85 183 89 137 116 78 115 197 125 ...</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ BloodPressure           : int  72 66 64 66 40 74 50 NA 70 96 ...</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ SkinThickness           : int  35 29 NA 23 35 NA 32 NA 45 NA ...</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ Insulin                 : int  NA NA NA 94 168 NA 88 NA 543 NA ...</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ BMI                     : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 NA ...</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ DiabetesPedigreeFunction: num  0.627 0.351 0.672 0.167 2.288 ...</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ Age                     : int  50 31 32 21 33 30 26 29 53 54 ...</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the dimensions</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(data)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 768   8</span></span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Reduce to a dataset of 400 observations to speed up model fitting.</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>train_obs <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(data), <span class="dv">400</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># X is our training sample.</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> data[train_obs, ]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a holdout set for evaluating model performance.</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: cross-validation is even better than a single holdout sample.</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>x_holdout <span class="ot">&lt;-</span> data[<span class="sc">-</span>train_obs, ]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># The outcome must be a numeric vector</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>outcome <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(outcome <span class="sc">==</span> <span class="st">&quot;yes&quot;</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> outcome[train_obs]</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>y_holdout <span class="ot">&lt;-</span> outcome[<span class="sc">-</span>train_obs]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the outcome variable distribution.</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(y_train, <span class="at">useNA =</span> <span class="st">&quot;ifany&quot;</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; y_train</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0   1 </span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 260 140</span></span></code></pre></div>
</div>
<div id="review-available-models" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Review available
models</h1>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>SuperLearner<span class="sc">::</span><span class="fu">listWrappers</span>()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All prediction algorithm wrappers in SuperLearner:</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;SL.bartMachine&quot;      &quot;SL.bayesglm&quot;         &quot;SL.biglasso&quot;        </span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [4] &quot;SL.caret&quot;            &quot;SL.caret.rpart&quot;      &quot;SL.cforest&quot;         </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] &quot;SL.earth&quot;            &quot;SL.extraTrees&quot;       &quot;SL.gam&quot;             </span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10] &quot;SL.gbm&quot;              &quot;SL.glm&quot;              &quot;SL.glm.interaction&quot; </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] &quot;SL.glmnet&quot;           &quot;SL.ipredbagg&quot;        &quot;SL.kernelKnn&quot;       </span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [16] &quot;SL.knn&quot;              &quot;SL.ksvm&quot;             &quot;SL.lda&quot;             </span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] &quot;SL.leekasso&quot;         &quot;SL.lm&quot;               &quot;SL.loess&quot;           </span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [22] &quot;SL.logreg&quot;           &quot;SL.mean&quot;             &quot;SL.nnet&quot;            </span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] &quot;SL.nnls&quot;             &quot;SL.polymars&quot;         &quot;SL.qda&quot;             </span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [28] &quot;SL.randomForest&quot;     &quot;SL.ranger&quot;           &quot;SL.ridge&quot;           </span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [31] &quot;SL.rpart&quot;            &quot;SL.rpartPrune&quot;       &quot;SL.speedglm&quot;        </span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [34] &quot;SL.speedlm&quot;          &quot;SL.step&quot;             &quot;SL.step.forward&quot;    </span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [37] &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot;          &quot;SL.svm&quot;             </span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [40] &quot;SL.template&quot;         &quot;SL.xgboost&quot;</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All screening algorithm wrappers in SuperLearner:</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;All&quot;</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;screen.corP&quot;           &quot;screen.corRank&quot;        &quot;screen.glmnet&quot;        </span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4] &quot;screen.randomForest&quot;   &quot;screen.SIS&quot;            &quot;screen.template&quot;      </span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [7] &quot;screen.ttest&quot;          &quot;write.screen.template&quot;</span></span></code></pre></div>
<p>Note that we add a new <code>grf</code> learner (<a href="https://grf-labs.github.io/grf/index.html">generalized random
forests</a>). Look at the code for a model.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>SL.grf</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (Y, X, newX, family, obsWeights, ...) </span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; {</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     .SL.require(&quot;grf&quot;)</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     if (family$family == &quot;gaussian&quot;) {</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         fit &lt;- grf::regression_forest(X, Y, sample.weights = obsWeights)</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         pred &lt;- stats::predict(fit, newX)$predictions</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     if (family$family == &quot;binomial&quot;) {</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         Y &lt;- as.factor(Y)</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         fit &lt;- grf::probability_forest(X, Y, sample.weights = obsWeights)</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         pred &lt;- stats::predict(fit, newX)$predictions[, &quot;1&quot;]</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     fit &lt;- list(object = fit)</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     class(fit) &lt;- c(&quot;SL.grf&quot;)</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     out &lt;- list(pred = pred, fit = fit)</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     return(out)</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; }</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &lt;bytecode: 0x1332df158&gt;</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &lt;environment: namespace:missSuperLearner&gt;</span></span></code></pre></div>
<p>For maximum accuracy one might try at least the following models:
glmnet, randomForest, XGBoost, SVM, and bartMachine. These should
ideally be tested with multiple hyperparameter settings for each
algorithm.</p>
</div>
<div id="fit-individual-models" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Fit individual
models</h1>
<p>Let’s fit 2 separate models: lasso (sparse, penalized OLS) and random
forest. We specify family = binomial() because we are predicting a
binary outcome, aka classification. With a continuous outcome we would
specify family = gaussian().</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lasso model</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>sl_lasso <span class="ot">&lt;-</span> <span class="fu">missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">SL.library =</span> <span class="st">&quot;SL.glmnet&quot;</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required namespace: mice</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required namespace: glmnet</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>sl_lasso</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = &quot;SL.glmnet&quot;,  </span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;, &quot;mice&quot;)) </span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                           Risk      Coef</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mean   0.1690821 0.8127358</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_median 0.1693482 0.0000000</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mice   0.1714403 0.1872642</span></span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the elements in the missSuperLearner object</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(sl_lasso)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;call&quot;              &quot;libraryNames&quot;      &quot;SL.library&quot;       </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [4] &quot;imputeAlgo&quot;        &quot;mice.params&quot;       &quot;X&quot;                </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] &quot;SL.predict&quot;        &quot;coef&quot;              &quot;library.predict&quot;  </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10] &quot;Z&quot;                 &quot;cvRisk&quot;            &quot;family&quot;           </span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] &quot;fitLibrary&quot;        &quot;cvFitLibrary&quot;      &quot;varNames&quot;         </span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [16] &quot;validRows&quot;         &quot;method&quot;            &quot;whichScreen&quot;      </span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] &quot;control&quot;           &quot;cvControl&quot;         &quot;errorsInCVLibrary&quot;</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [22] &quot;errorsInLibrary&quot;   &quot;metaOptimizer&quot;     &quot;env&quot;              </span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] &quot;times&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the risk of the best model (discrete SuperLearner winner).</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>sl_lasso<span class="sc">$</span>cvRisk[<span class="fu">which.min</span>(sl_lasso<span class="sc">$</span>cvRisk)]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mean </span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.1690821</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here is the raw glmnet result object:</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(sl_lasso<span class="sc">$</span>fitLibrary<span class="sc">$</span>SL.glmnet_All_mean<span class="sc">$</span>object, <span class="at">max.level =</span> <span class="dv">1</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; List of 12</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ lambda    : num [1:62] 0.211 0.193 0.175 0.16 0.146 ...</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ cvm       : num [1:62] 1.31 1.28 1.26 1.23 1.21 ...</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ cvsd      : num [1:62] 0.0555 0.0551 0.0519 0.0493 0.0473 ...</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ cvup      : num [1:62] 1.36 1.34 1.31 1.28 1.26 ...</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ cvlo      : num [1:62] 1.25 1.23 1.2 1.18 1.17 ...</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ nzero     : Named int [1:62] 0 1 1 1 1 1 1 1 3 3 ...</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..- attr(*, &quot;names&quot;)= chr [1:62] &quot;s0&quot; &quot;s1&quot; &quot;s2&quot; &quot;s3&quot; ...</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ call      : language glmnet::cv.glmnet(x = X, y = Y, weights = obsWeights, lambda = NULL, type.measure = loss,      nfolds = nfolds, f| __truncated__</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ name      : Named chr &quot;Binomial Deviance&quot;</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..- attr(*, &quot;names&quot;)= chr &quot;deviance&quot;</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ glmnet.fit:List of 13</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;lognet&quot; &quot;glmnet&quot;</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ lambda.min: num 0.00894</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ lambda.1se: num 0.0575</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ index     : int [1:2, 1] 35 15</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  - attr(*, &quot;class&quot;)= chr &quot;cv.glmnet&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit random forest.</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>sl_rf <span class="ot">&lt;-</span> <span class="fu">missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">SL.library =</span> <span class="st">&quot;SL.ranger&quot;</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required namespace: ranger</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>sl_rf</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = &quot;SL.ranger&quot;,  </span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;, &quot;mice&quot;)) </span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                           Risk Coef</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_mean   0.1660411    1</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_median 0.1691019    0</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_mice   0.1721956    0</span></span></code></pre></div>
<p>Risk is a measure of model accuracy or performance. We want our
models to minimize the estimated risk, which means the model is making
the fewest mistakes in its prediction. It’s basically the mean-squared
error in a regression model, but you can customize it if you want.</p>
<p>SuperLearner is using cross-validation to estimate the risk on future
data. By default it uses 10 folds; use the cvControl argument to
customize.</p>
<p>The coefficient column tells us the weight or importance of each
individual learner in the overall ensemble. By default the weights are
always greater than or equal to 0 and sum to 1. In this case we only
have one algorithm so the coefficient has to be 1. If a coefficient is 0
it means that the algorithm isn’t being used in the SuperLearner
ensemble.</p>
</div>
<div id="fit-multiple-models" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Fit multiple
models</h1>
<p>Instead of fitting the models separately and looking at the
performance (lowest risk), we can fit them simultaneously. SuperLearner
will then tell us which one is best (discrete winner) and also create a
weighted average of multiple models.</p>
<p>We include the mean of Y (“SL.mean”) as a benchmark algorithm. It is
a very simple prediction so the more complex algorithms should do better
than the sample mean. We hope to see that it isn’t the best single
algorithm (discrete winner) and has a low weight in the weighted-average
ensemble. If it is the best algorithm something has likely gone
wrong.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>sl <span class="ot">&lt;-</span> <span class="fu">missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;SL.ranger&quot;</span>))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>sl</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  </span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;), imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;, &quot;mice&quot;)) </span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                           Risk       Coef</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.mean_All_raw      0.2280864 0.00000000</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mean   0.1692748 0.00000000</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_median 0.1687926 0.54694438</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mice   0.1714224 0.00000000</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_mean   0.1706635 0.35995406</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_median 0.1708190 0.07833690</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_mice   0.1727597 0.01476465</span></span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review how long it took to run the SuperLearner:</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>sl<span class="sc">$</span>times<span class="sc">$</span>everything</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    user  system elapsed </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   5.566   0.237   5.547</span></span></code></pre></div>
<p>Again, the coefficient is how much weight SuperLearner puts on that
model in the weighted-average. So if coefficient = 0 it means that model
is not used at all. Here we see that random forest is given the most
weight, following by lasso.</p>
<p>So we have an automatic ensemble of multiple learners based on the
cross-validated performance of those learners, nice!</p>
</div>
<div id="predict-on-new-data" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Predict on new
data</h1>
<p>Now that we have an ensemble let’s predict back on our holdout
dataset and review the results.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict back on the holdout dataset.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># onlySL is set to TRUE so we don&#39;t fit algorithms that had weight = 0, saving computation.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(sl, <span class="at">newdata =</span> x_holdout, <span class="at">X =</span> x_train, <span class="at">onlySL =</span> <span class="cn">TRUE</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the structure of this prediction object.</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(pred)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; List of 2</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ pred           : num [1:368, 1] 0.0421 0.1714 0.0836 0.4969 0.5972 ...</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ library.predict: num [1:368, 1:7] 0 0 0 0 0 0 0 0 0 0 ...</span></span></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the columns of $library.predict.</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pred<span class="sc">$</span>library.predict)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        V1          V2          V3                V4          V5        </span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   :0   Min.   :0   Min.   :0.02655   Min.   :0   Min.   :0.0000  </span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:0   1st Qu.:0   1st Qu.:0.14315   1st Qu.:0   1st Qu.:0.1354  </span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median :0   Median :0   Median :0.27936   Median :0   Median :0.2745  </span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   :0   Mean   :0   Mean   :0.34220   Mean   :0   Mean   :0.3422  </span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:0   3rd Qu.:0   3rd Qu.:0.47399   3rd Qu.:0   3rd Qu.:0.5337  </span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :0   Max.   :0   Max.   :0.95580   Max.   :0   Max.   :0.8900  </span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        V6               V7        </span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   :0.0020   Min.   :0.0020  </span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:0.1435   1st Qu.:0.1240  </span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median :0.2873   Median :0.2690  </span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   :0.3471   Mean   :0.3320  </span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:0.5367   3rd Qu.:0.5145  </span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :0.8946   Max.   :0.9220</span></span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of our predicted values.</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(pred<span class="sc">$</span>pred[, <span class="dv">1</span>]) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot of original values (0, 1) and predicted values.</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Ideally we would use jitter or slight transparency to deal with overlap.</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(y_holdout, pred<span class="sc">$</span>pred[, <span class="dv">1</span>]) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review AUC - Area Under Curve</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>pred_rocr <span class="ot">&lt;-</span> ROCR<span class="sc">::</span><span class="fu">prediction</span>(pred<span class="sc">$</span>pred, y_holdout)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>auc <span class="ot">&lt;-</span> ROCR<span class="sc">::</span><span class="fu">performance</span>(pred_rocr, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>, <span class="at">x.measure =</span> <span class="st">&quot;cutoff&quot;</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>auc</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.856543</span></span></code></pre></div>
<p>AUC can range from 0.5 (no better than chance) to 1.0 (perfect). So
at 0.85 we are looking pretty good!</p>
</div>
<div id="fit-ensemble-with-external-cross-validation" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Fit ensemble with
external cross-validation</h1>
<p>What we don’t have yet is an estimate of the performance of the
ensemble itself. Right now we are just hopeful that the ensemble weights
are successful in improving over the best single algorithm.</p>
<p>In order to estimate the performance of the SuperLearner ensemble we
need an “external” layer of cross-validation, also called nested
cross-validation. We generate a separate holdout sample that we don’t
use to fit the SuperLearner, which allows it to be a good estimate of
the SuperLearner’s performance on unseen data. Typically we would run 10
or 20-fold external cross-validation, but even 5-fold is reasonable.</p>
<p>Another nice result is that we get standard errors on the performance
of the individual algorithms and can compare them to the
SuperLearner.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Don&#39;t have timing info for the CV.SuperLearner unfortunately.</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># So we need to time it manually.</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># This will take about 2x as long as the previous SuperLearner.</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>                               <span class="co"># For a real analysis we would use V = 10.</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>                               <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">2</span>), <span class="at">innerCvControl =</span> <span class="fu">list</span>(<span class="fu">list</span>(<span class="at">V=</span><span class="dv">2</span>)),</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>                               <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>                               <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;SL.ranger&quot;</span>))</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Warning in CV.missSuperLearner(Y = y_train, X = x_train, family = binomial(), :</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Only a single innerCvControl is given, will be replicated across all cross-</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; validation split calls to missSuperLearner</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    user  system elapsed </span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   1.880   0.099   1.792</span></span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We run summary on the cv_sl object rather than simply printing the object.</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv_sl)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; CV.missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  </span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;SL.glmnet&quot;, &quot;SL.ranger&quot;), imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;, &quot;mice&quot;),  </span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     cvControl = list(V = 2), innerCvControl = list(list(V = 2))) </span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Risk is based on: Mean Squared Error</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All risk estimates are based on V =  2 </span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Algorithm     Ave        se     Min     Max</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         Super Learner 0.17580 0.0100311 0.15761 0.19400</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           Discrete SL 0.17687 0.0104065 0.15802 0.19573</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       SL.mean_All_raw 0.22818 0.0072133 0.22368 0.23268</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_All_mean 0.17304 0.0106829 0.15802 0.18807</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.glmnet_All_median 0.17261 0.0108009 0.15741 0.18781</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_All_mice 0.17342 0.0102748 0.15627 0.19057</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_All_mean 0.18294 0.0101310 0.17015 0.19573</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.ranger_All_median 0.18133 0.0100726 0.16825 0.19440</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_All_mice 0.18282 0.0099762 0.16827 0.19736</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the distribution of the best single learner as external CV folds.</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">simplify2array</span>(cv_sl<span class="sc">$</span>whichDiscreteSL))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mean SL.ranger_All_mean </span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                  1                  1</span></span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the performance with 95% CIs (use a better ggplot theme).</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv_sl) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>We see two SuperLearner results: “Super Learner” and “Discrete SL”.
“Discrete SL” chooses the best single learner - in this case SL.glmnet
(lasso). “Super Learner” takes a weighted average of the learners using
the coefficients/weights that we examined earlier. In general “Super
Learner” should perform a little better than “Discrete SL”.</p>
<p>We see based on the outer cross-validation that SuperLearner is
statistically tying with the best algorithm. Our benchmark learner
“SL.mean” shows that we get a nice improvement over a naive guess based
only on the mean. We could also add “SL.glm” to compare to logistic
regression.</p>
</div>
<div id="customize-a-model-hyperparameter" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Customize a model
hyperparameter</h1>
<p>Hyperparameters are the configuration settings for an algorithm. OLS
has no hyperparameters but essentially every other algorithm does.</p>
<p>There are two ways to customize a hyperparameter: make a new learner
function, or use create.Learner().</p>
<p>Let’s make a variant of random forest that fits more trees, which may
increase our accuracy and can’t hurt it (outside of small random
variation).</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the function argument defaults at the top.</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>SL.ranger</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (Y, X, newX, family, obsWeights, num.trees = 500, mtry = floor(sqrt(ncol(X))), </span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     write.forest = TRUE, probability = family$family == &quot;binomial&quot;, </span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     min.node.size = ifelse(family$family == &quot;gaussian&quot;, 5, 1), </span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     replace = TRUE, sample.fraction = ifelse(replace, 1, 0.632), </span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     num.threads = 1, verbose = T, ...) </span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; {</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     .SL.require(&quot;ranger&quot;)</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     if (family$family == &quot;binomial&quot;) {</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         Y = as.factor(Y)</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     if (is.matrix(X)) {</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         X = data.frame(X)</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     fit &lt;- ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), </span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         num.trees = num.trees, mtry = mtry, min.node.size = min.node.size, </span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         replace = replace, sample.fraction = sample.fraction, </span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         case.weights = obsWeights, write.forest = write.forest, </span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         probability = probability, num.threads = num.threads, </span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         verbose = verbose)</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     pred &lt;- predict(fit, data = newX)$predictions</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     if (family$family == &quot;binomial&quot;) {</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         pred = pred[, &quot;1&quot;]</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     fit &lt;- list(object = fit, verbose = verbose)</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     class(fit) &lt;- c(&quot;SL.ranger&quot;)</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     out &lt;- list(pred = pred, fit = fit)</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     return(out)</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; }</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &lt;bytecode: 0x120cf2948&gt;</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &lt;environment: namespace:SuperLearner&gt;</span></span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new function that changes just the ntree argument.</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (We could do this in a single line.)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># &quot;...&quot; means &quot;all other arguments that were sent to the function&quot;</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>SL.rf.better <span class="ot">=</span> <span class="cf">function</span>(...) {</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">SL.ranger</span>(..., <span class="at">num.trees =</span> <span class="dv">1000</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the CV.SuperLearner.</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># We use V = 3 to save computation time; for a real analysis use V = 10 or 20.</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(), <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V=</span><span class="dv">3</span>),</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>                             <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>                             <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;SL.rf.better&quot;</span>, <span class="st">&quot;SL.ranger&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review results.</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv_sl)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; CV.missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  </span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;SL.glmnet&quot;, &quot;SL.rf.better&quot;, &quot;SL.ranger&quot;), imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;,  </span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;mice&quot;), cvControl = list(V = 3)) </span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Risk is based on: Mean Squared Error</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All risk estimates are based on V =  3 </span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                Algorithm     Ave        se     Min     Max</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            Super Learner 0.16979 0.0098089 0.16167 0.17771</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              Discrete SL 0.17243 0.0105484 0.16288 0.18122</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          SL.mean_All_raw 0.22863 0.0072248 0.21984 0.24188</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       SL.glmnet_All_mean 0.17207 0.0103712 0.16121 0.18122</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     SL.glmnet_All_median 0.17110 0.0104618 0.16069 0.17943</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       SL.glmnet_All_mice 0.17239 0.0102227 0.16288 0.18113</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.rf.better_All_mean 0.17323 0.0098295 0.17067 0.17533</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.rf.better_All_median 0.17324 0.0098739 0.17200 0.17525</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.rf.better_All_mice 0.17780 0.0098309 0.16839 0.18345</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       SL.ranger_All_mean 0.17498 0.0100178 0.17142 0.17814</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     SL.ranger_All_median 0.17577 0.0100110 0.17327 0.17727</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       SL.ranger_All_mice 0.17814 0.0098391 0.17014 0.18280</span></span></code></pre></div>
<p>Looks like our new RF is not improving performance. This implies that
the original 500 trees had already reached the performance plateau - a
maximum accuracy that RF can achieve unless other settings are changed
(e.g. max nodes).</p>
<p>For comparison we can do the same hyperparameter customization with
create.Learner().</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Customize the defaults for random forest.</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">&lt;-</span> <span class="fu">create.Learner</span>(<span class="st">&quot;SL.ranger&quot;</span>, <span class="at">params =</span> <span class="fu">list</span>(<span class="at">num.trees =</span> <span class="dv">1000</span>))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the object.</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>learners</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $grid</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; NULL</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $names</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;SL.ranger_1&quot;</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $base_learner</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;SL.ranger&quot;</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $params</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $params$num.trees</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1000</span></span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># List the functions that were created</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>learners<span class="sc">$</span>names</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;SL.ranger_1&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the code that was automatically generated for the function.</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice that it&#39;s exactly the same as the function we made manually.</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>SL.ranger_1</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (...) </span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger(..., num.trees = 1000)</span></span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the CV.SuperLearner.</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We use V = 3 to save computation time; for a real analysis use V = 10 or 20.</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(), <span class="at">V =</span> <span class="dv">3</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                             <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, learners<span class="sc">$</span>names, <span class="st">&quot;SL.ranger&quot;</span>))</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Review results.</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv_sl)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; CV.missSuperLearner(Y = y_train, X = x_train, V = 3, family = binomial(),  </span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     SL.library = c(&quot;SL.mean&quot;, &quot;SL.glmnet&quot;, learners$names, &quot;SL.ranger&quot;),  </span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;, &quot;mice&quot;)) </span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Risk is based on: Mean Squared Error</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All risk estimates are based on V =  3 </span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               Algorithm     Ave        se     Min     Max</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           Super Learner 0.16979 0.0098089 0.16167 0.17771</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Discrete SL 0.17243 0.0105484 0.16288 0.18122</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         SL.mean_All_raw 0.22863 0.0072248 0.21984 0.24188</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.glmnet_All_mean 0.17207 0.0103712 0.16121 0.18122</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_All_median 0.17110 0.0104618 0.16069 0.17943</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.glmnet_All_mice 0.17239 0.0102227 0.16288 0.18113</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_1_All_mean 0.17323 0.0098295 0.17067 0.17533</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.ranger_1_All_median 0.17324 0.0098739 0.17200 0.17525</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_1_All_mice 0.17780 0.0098309 0.16839 0.18345</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.ranger_All_mean 0.17498 0.0100178 0.17142 0.17814</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_All_median 0.17577 0.0100110 0.17327 0.17727</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.ranger_All_mice 0.17814 0.0098391 0.17014 0.18280</span></span></code></pre></div>
<p>We get exactly the same results between the two methods of creating a
custom learner.</p>
</div>
<div id="test-algorithm-with-multiple-hyperparameter-settings" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Test algorithm with
multiple hyperparameter settings</h1>
<p>The performance of an algorithm varies based on its hyperparamters,
which again are its configuration settings. Some algorithms may not vary
much, and others might have far better or worse performance for certain
settings. Often we focus our attention on 1 or 2 hyperparameters for a
given algorithm because they are the most important ones.</p>
<p>For random forest there are two particularly important
hyperparameters: mtry and maximum leaf nodes. Mtry is how many features
are randomly chosen within each decision tree node - in other words,
each time the tree considers making a split. Maximum leaf nodes controls
how complex each tree can get.</p>
<p>Let’s try 3 different mtry options.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sqrt(p) is the default value of mtry for classification.</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">floor</span>(<span class="fu">sqrt</span>(<span class="fu">ncol</span>(x_train)))</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 2</span></span></code></pre></div>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s try 3 multiplies of this default: 0.5, 1, and 2.</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>(mtry_seq <span class="ot">&lt;-</span> <span class="fu">floor</span>(<span class="fu">sqrt</span>(<span class="fu">ncol</span>(x_train)) <span class="sc">*</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">2</span>)))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1 2 5</span></span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">&lt;-</span> <span class="fu">create.Learner</span>(<span class="st">&quot;SL.ranger&quot;</span>, <span class="at">tune =</span> <span class="fu">list</span>(<span class="at">mtry =</span> mtry_seq))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the resulting object</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>learners</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $grid</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   mtry</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    1</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    2</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3    5</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $names</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;SL.ranger_1&quot; &quot;SL.ranger_2&quot; &quot;SL.ranger_3&quot;</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $base_learner</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;SL.ranger&quot;</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $params</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; list()</span></span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check code for the learners that were created.</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>SL.ranger_1</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (...) </span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger(..., mtry = 1)</span></span></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>SL.ranger_2</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (...) </span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger(..., mtry = 2)</span></span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>SL.ranger_3</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (...) </span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger(..., mtry = 5)</span></span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the CV.SuperLearner.</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We use V = 3 to save computation time; for a real analysis use V = 10 or 20.</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(), <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">3</span>),</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>                             <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, learners<span class="sc">$</span>names, <span class="st">&quot;SL.ranger&quot;</span>))</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Review results.</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv_sl)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; CV.missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = c(&quot;SL.mean&quot;,  </span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;SL.glmnet&quot;, learners$names, &quot;SL.ranger&quot;), imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;,  </span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;mice&quot;), cvControl = list(V = 3)) </span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Risk is based on: Mean Squared Error</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All risk estimates are based on V =  3 </span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               Algorithm     Ave        se     Min     Max</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           Super Learner 0.16926 0.0095981 0.16027 0.17684</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Discrete SL 0.17132 0.0100570 0.15912 0.18185</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         SL.mean_All_raw 0.22863 0.0072248 0.21984 0.24188</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.glmnet_All_mean 0.17128 0.0101996 0.16121 0.17965</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_All_median 0.17191 0.0101367 0.16100 0.18185</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.glmnet_All_mice 0.17166 0.0099010 0.15912 0.18269</span></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_1_All_mean 0.17440 0.0091668 0.17195 0.17775</span></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.ranger_1_All_median 0.17389 0.0091203 0.16960 0.17724</span></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_1_All_mice 0.17616 0.0089387 0.17296 0.18102</span></span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_2_All_mean 0.17408 0.0098549 0.17045 0.17692</span></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.ranger_2_All_median 0.17568 0.0099911 0.17422 0.17648</span></span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_2_All_mice 0.17552 0.0096293 0.16955 0.18218</span></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_3_All_mean 0.17859 0.0108938 0.17303 0.18743</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.ranger_3_All_median 0.17996 0.0110236 0.17234 0.18983</span></span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_3_All_mice 0.17841 0.0104559 0.16661 0.19199</span></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.ranger_All_mean 0.17550 0.0099923 0.17336 0.17762</span></span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.ranger_All_median 0.17376 0.0099066 0.17151 0.17611</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      SL.ranger_All_mice 0.17525 0.0096016 0.17060 0.17925</span></span></code></pre></div>
<p>We see here that mtry = 7 performed a little bit better than mtry = 1
or mtry = 3, although the difference is not significant. If we used more
data and more cross-validation folds we might see more drastic
differences. A higher mtry does better when a small percentage of
variables are predictive of the outcome, because it gives each tree a
better chance of finding a useful variable.</p>
<p>Note that SL.ranger and SL.ranger_2 have the same settings, and their
performance is very similar - statistically a tie. It’s not exactly
equivalent due to random variation in the two forests.</p>
<p>A key difference with SuperLearner over caret or other frameworks is
that we are not trying to choose the single best hyperparameter or
model. Instead, we usually want the best weighted average. So we are
including all of the different settings in our SuperLearner, and we may
choose a weighted average that includes the same model multiple times
but with different settings. That can give us better performance than
choosing only the single best settings for a given algorithm, which has
some random noise in any case.</p>
</div>
<div id="multicore-parallelization" class="section level1" number="10">
<h1><span class="header-section-number">10</span> Multicore
parallelization</h1>
</div>
<div id="weight-distribution-for-superlearner" class="section level1" number="11">
<h1><span class="header-section-number">11</span> Weight distribution
for SuperLearner</h1>
<p>The weights or coefficients of the SuperLearner are stochastic - they
will change as the data changes. So we don’t necessarily trust a given
set of weights as being the “true” weights, but when we use
CV.SuperLearner we at least have multiple samples from the distribution
of the weights.</p>
<p>We can write a little function to extract the weights at each
CV.SuperLearner iteration and summarize the distribution of those
weights. This may be added to the SuperLearner package sometime in the
future.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review meta-weights (coefficients) from a CV.SuperLearner object</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>review_weights <span class="ot">=</span> <span class="cf">function</span>(cv_sl) {</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  meta_weights <span class="ot">=</span> <span class="fu">coef</span>(cv_sl)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  means <span class="ot">=</span> <span class="fu">colMeans</span>(meta_weights)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  sds <span class="ot">=</span> <span class="fu">apply</span>(meta_weights, <span class="at">MARGIN =</span> <span class="dv">2</span>,  <span class="at">FUN =</span> sd)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  mins <span class="ot">=</span> <span class="fu">apply</span>(meta_weights, <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> min)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  maxs <span class="ot">=</span> <span class="fu">apply</span>(meta_weights, <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> max)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine the stats into a single matrix.</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  sl_stats <span class="ot">=</span> <span class="fu">cbind</span>(<span class="st">&quot;mean(weight)&quot;</span> <span class="ot">=</span> means, <span class="st">&quot;sd&quot;</span> <span class="ot">=</span> sds, <span class="st">&quot;min&quot;</span> <span class="ot">=</span> mins, <span class="st">&quot;max&quot;</span> <span class="ot">=</span> maxs)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sort by decreasing mean weight.</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>  sl_stats[<span class="fu">order</span>(sl_stats[, <span class="dv">1</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>), ]</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">review_weights</span>(cv_sl), <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                        mean(weight)       sd   min     max</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_median       0.350803 0.185455 0.147 0.50901</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mice         0.196103 0.272999 0.000 0.50790</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.glmnet_All_mean         0.177373 0.227201 0.000 0.43346</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_median       0.153716 0.156011 0.000 0.31192</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_1_All_median     0.121444 0.192760 0.000 0.34370</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_1_All_mean       0.000562 0.000973 0.000 0.00169</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.mean_All_raw            0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_1_All_mice       0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_2_All_mean       0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_2_All_median     0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_2_All_mice       0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_3_All_mean       0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_3_All_median     0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_3_All_mice       0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_mean         0.000000 0.000000 0.000 0.00000</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; SL.ranger_All_mice         0.000000 0.000000 0.000 0.00000</span></span></code></pre></div>
<p>Notice that in this case the ensemble never uses the mean nor the
randomForest with mtry = 1. Also the LASSO (glmnet) was only used on a
subset of the folds. Adding multiple configurations of randomForest was
helpful because mtry = 7 was used. However, based on the minimum column
we can see that no algorithm was used every single time.</p>
<p>We recommend reviewing the weight distribution for any SuperLearner
project to better understand which algorithms are chosen for the
ensemble.</p>
</div>
<div id="feature-selection-screening" class="section level1" number="12">
<h1><span class="header-section-number">12</span> Feature selection
(screening)</h1>
<p>When datasets have many covariates our algorithms may benefit from
first choosing a subset of available covariates, a step called feature
selection. Then we pass only those variables to the modeling algorithm,
and it may be less likely to overfit to variables that are not related
to the outcome.</p>
<p>Let’s revisit listWrappers() and check out the bottom section.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>SuperLearner<span class="sc">::</span><span class="fu">listWrappers</span>()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All prediction algorithm wrappers in SuperLearner:</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;SL.bartMachine&quot;      &quot;SL.bayesglm&quot;         &quot;SL.biglasso&quot;        </span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [4] &quot;SL.caret&quot;            &quot;SL.caret.rpart&quot;      &quot;SL.cforest&quot;         </span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] &quot;SL.earth&quot;            &quot;SL.extraTrees&quot;       &quot;SL.gam&quot;             </span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10] &quot;SL.gbm&quot;              &quot;SL.glm&quot;              &quot;SL.glm.interaction&quot; </span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] &quot;SL.glmnet&quot;           &quot;SL.ipredbagg&quot;        &quot;SL.kernelKnn&quot;       </span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [16] &quot;SL.knn&quot;              &quot;SL.ksvm&quot;             &quot;SL.lda&quot;             </span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] &quot;SL.leekasso&quot;         &quot;SL.lm&quot;               &quot;SL.loess&quot;           </span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [22] &quot;SL.logreg&quot;           &quot;SL.mean&quot;             &quot;SL.nnet&quot;            </span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] &quot;SL.nnls&quot;             &quot;SL.polymars&quot;         &quot;SL.qda&quot;             </span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [28] &quot;SL.randomForest&quot;     &quot;SL.ranger&quot;           &quot;SL.ridge&quot;           </span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [31] &quot;SL.rpart&quot;            &quot;SL.rpartPrune&quot;       &quot;SL.speedglm&quot;        </span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [34] &quot;SL.speedlm&quot;          &quot;SL.step&quot;             &quot;SL.step.forward&quot;    </span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [37] &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot;          &quot;SL.svm&quot;             </span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [40] &quot;SL.template&quot;         &quot;SL.xgboost&quot;</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All screening algorithm wrappers in SuperLearner:</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;All&quot;</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;screen.corP&quot;           &quot;screen.corRank&quot;        &quot;screen.glmnet&quot;        </span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4] &quot;screen.randomForest&quot;   &quot;screen.SIS&quot;            &quot;screen.template&quot;      </span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [7] &quot;screen.ttest&quot;          &quot;write.screen.template&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Review code for corP, which is based on univariate correlation.</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>screen.corP</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; function (Y, X, family, obsWeights, id, method = &quot;pearson&quot;, minPvalue = 0.1, </span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     minscreen = 2, ...) </span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; {</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     listp &lt;- apply(X, 2, function(x, Y, method) {</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         ifelse(var(x) &lt;= 0, 1, cor.test(x, y = Y, method = method)$p.value)</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }, Y = Y, method = method)</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     whichVariable &lt;- (listp &lt;= minPvalue)</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     if (sum(whichVariable) &lt; minscreen) {</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         warning(&quot;number of variables with p value less than minPvalue is less than minscreen&quot;)</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         whichVariable[rank(listp) &lt;= minscreen] &lt;- TRUE</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     }</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     return(whichVariable)</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; }</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &lt;bytecode: 0x134a8cfc0&gt;</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &lt;environment: namespace:SuperLearner&gt;</span></span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the SuperLearner.</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to use list() instead of c().</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>                             <span class="co"># For a real analysis we would use V = 10.</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>                             <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">3</span>),</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>                             <span class="at">parallel =</span> <span class="st">&quot;multicore&quot;</span>,</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>                             <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>                             <span class="at">SL.library =</span> <span class="fu">list</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;screen.corP&quot;</span>)))</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required namespace: parallel</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv_sl)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; CV.missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = list(&quot;SL.mean&quot;,  </span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;SL.glmnet&quot;, c(&quot;SL.glmnet&quot;, &quot;screen.corP&quot;)), imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;,  </span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;mice&quot;), cvControl = list(V = 3), parallel = &quot;multicore&quot;) </span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Risk is based on: Mean Squared Error</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All risk estimates are based on V =  3 </span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                     Algorithm     Ave        se     Min     Max</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                 Super Learner 0.17137 0.0100112 0.16307 0.18053</span></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                   Discrete SL 0.17221 0.0102640 0.16307 0.18070</span></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               SL.mean_All_raw 0.22863 0.0072248 0.21984 0.24188</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            SL.glmnet_All_mean 0.17143 0.0103450 0.16084 0.18027</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          SL.glmnet_All_median 0.17185 0.0101099 0.16083 0.18185</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            SL.glmnet_All_mice 0.17223 0.0099433 0.16307 0.18472</span></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_screen.corP_mean 0.17069 0.0096896 0.16084 0.18070</span></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.glmnet_screen.corP_median 0.17004 0.0097957 0.16083 0.17943</span></span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_screen.corP_mice 0.17326 0.0098651 0.16289 0.18530</span></span></code></pre></div>
<p>We see a small performance boost by first screening by univarate
correlation with our outcome, and only keeping variables with a p-value
less than 0.10. Try using some of the other screening algorithms as they
may do even better for a particular dataset.</p>
</div>
<div id="optimize-for-auc" class="section level1" number="13">
<h1><span class="header-section-number">13</span> Optimize for AUC</h1>
<p>For binary prediction we are typically trying to maximize AUC, which
can be the best performance metric when our outcome variable has some
imbalance. In other words, we don’t have exactly 50% 1s and 50% 0s in
our outcome. Our SuperLearner is not targeting AUC by default, but it
can if we tell it to by specifying our method.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.missSuperLearner</span>(<span class="at">Y =</span> y_train, <span class="at">X =</span> x_train, <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                             <span class="co"># For a real analysis we would use V = 10.</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">3</span>),</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">method =</span> <span class="st">&quot;method.AUC&quot;</span>,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>                             <span class="at">imputeAlgo =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;mice&quot;</span>),</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>                             <span class="at">SL.library =</span> <span class="fu">list</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;screen.corP&quot;</span>)))</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Loading required package: cvAUC</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv_sl)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:  </span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; CV.missSuperLearner(Y = y_train, X = x_train, family = binomial(), SL.library = list(&quot;SL.mean&quot;,  </span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;SL.glmnet&quot;, c(&quot;SL.glmnet&quot;, &quot;screen.corP&quot;)), imputeAlgo = c(&quot;mean&quot;, &quot;median&quot;,  </span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &quot;mice&quot;), method = &quot;method.AUC&quot;, cvControl = list(V = 3)) </span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Risk is based on: Area under ROC curve (AUC)</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All risk estimates are based on V =  3 </span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                     Algorithm     Ave se     Min     Max</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                 Super Learner 0.80368 NA 0.77025 0.82336</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                   Discrete SL 0.80028 NA 0.77358 0.81389</span></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               SL.mean_All_raw 0.50000 NA 0.50000 0.50000</span></span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            SL.glmnet_All_mean 0.80225 NA 0.77358 0.81742</span></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          SL.glmnet_All_median 0.80086 NA 0.77051 0.81869</span></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            SL.glmnet_All_mice 0.79531 NA 0.75748 0.81458</span></span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_screen.corP_mean 0.80732 NA 0.77358 0.83072</span></span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  SL.glmnet_screen.corP_median 0.80774 NA 0.77460 0.83120</span></span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    SL.glmnet_screen.corP_mice 0.79259 NA 0.75236 0.81414</span></span></code></pre></div>
<p>This conveniently shows us the AUC for each algorithm without us
having to calculate it manually. But we aren’t getting SEs sadly.</p>
<p>Another important optimizer to consider is negative log likelihood,
which is intended for binary outcomes and will often work better than
NNLS (the default). This is specified by method = “NNloglik”.</p>
</div>
<div id="references" class="section level1" number="14">
<h1><span class="header-section-number">14</span> References</h1>
<p>Kennedy, C. (2017). <strong>Guide to SuperLearner.</strong>
<em>R-Project</em>. <a href="https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html" class="uri">https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html</a></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
